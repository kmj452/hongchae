<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
    <script defer src="https://pyscript.net/latest/pyscript.js"></script>
    <!-- 파일 or 패키지 불러오기 -->
    <!-- <py-env> -->
        <!-- - numpy -->
        <!-- - matplotlib -->
        <!-- - paths: --> <!-- 방법 1. 파이썬 파일 경로 사용해서 불러올 수 있음 -->
            <!-- - ./main.py -->
    <!-- </py-env> -->
    <py-config type="json">
        {
          "packages": ["numpy", "matplotlib", "micropip"]
        }
      </py-config>

    <title>Test Web</title>
</head>
<!-- 인라인 코드 작성-->
<!-- <py-repl></py-repl> -->
<body>
    <h1>Test</h1>
    <!-- 방법 2. <py-script src="./main.py"></py-script> -> 파이썬 파일 가져오기 -->
    <div id="plot"></div>
    <py-script>
        import torch
        import cv2
        import numpy as np
        import sys
        from pathlib import Path
        
        # YOLOv5 저장소 경로 추가
        sys.path.append('C:\\Users\\toror\\Downloads\\hongchae-parkhyun\\yolov5')
        
        from models.common import DetectMultiBackend
        from utils.general import non_max_suppression
        from utils.torch_utils import select_device
        
        # scale_coords 함수 정의
        def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):
            if ratio_pad is None:
                gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])
                pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2
            else:
                gain = ratio_pad[0][0]
                pad = ratio_pad[1]
        
            coords[:, [0, 2]] -= pad[0]
            coords[:, [1, 3]] -= pad[1]
            coords[:, :4] /= gain
            coords[:, 0].clamp_(0, img0_shape[1])
            coords[:, 1].clamp_(0, img0_shape[0])
            coords[:, 2].clamp_(0, img0_shape[1])
            coords[:, 3].clamp_(0, img0_shape[0])
            return coords
        
        # YOLOv5 모델 로드
        model_path = "C:\\Users\\toror\\Downloads\\hongchae-parkhyun\\yolov5\\runs\\train\\exp\\weights\\best.pt"
        device = select_device('cpu')
        model = DetectMultiBackend(weights=str(model_path), device=device)
        
        # Haar Cascade 로드
        eye_cascade_path = cv2.data.haarcascades + 'haarcascade_eye.xml'
        eye_cascade = cv2.CascadeClassifier(eye_cascade_path)
        
        # 웹캠에서 실시간 비디오 스트림 캡처
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("Error: Could not open video stream.")
            sys.exit()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
        
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            eyes = eye_cascade.detectMultiScale(gray, 1.3, 5)
            
            for (x, y, w, h) in eyes:
                roi_color = frame[y:y+h, x:x+w]
                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)
        
                # YOLOv5를 사용하여 추가 분석 수행
                img = cv2.resize(roi_color, (640, 640))
                img = img[:, :, ::-1].transpose(2, 0, 1)
                img = np.ascontiguousarray(img)
        
                img = torch.from_numpy(img).to(device)
                img = img.float()
                img /= 255.0
                if img.ndimension() == 3:
                    img = img.unsqueeze(0)
        
                # 추론
                pred = model(img, augment=False, visualize=False)
                pred = non_max_suppression(pred, 0.25, 0.45, None, False, max_det=1000)
        
                # 바운딩 박스 그리기 및 객체 인식 확인
                for i, det in enumerate(pred):
                    if len(det):
                        det[:, :4] = scale_coords(img.shape[2:], det[:, :4], roi_color.shape).round()
        
                        for *xyxy, conf, cls in reversed(det):
                            if conf > 0.5:
                                cv2.rectangle(roi_color, (int(xyxy[0]), int(xyxy[1])), (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)
                                label = f"Iris: {conf:.2f}"
                                cv2.putText(roi_color, label, (int(xyxy[0]), int(xyxy[1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
            # 결과 프레임 표시
            cv2.imshow('Eye Detection', frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
        
    </py-script>
</body>
</html>s