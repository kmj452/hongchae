{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68536ae4-6b39-4dad-a166-c9c7e9698920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "#미디어파이프를 이용해서 홍채영역 실시간 트래킹\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 웹캠 입력을 받습니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # 성능을 향상시키기 위해 이미지를 쓰지 않고 참조합니다.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # 이미지에 출력을 그리기 위해 다시 이미지를 BGR로 변환합니다.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 강조하기 위해 주요 랜드마크를 표시합니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "            for landmark in iris_landmarks:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow('MediaPipe Iris Tracking', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6068ace-5518-42e2-85d2-8a2382fa08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진 입력시 홍채영역 마킹\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "def mark_iris(input_image_path, output_image_path):\n",
    "    # 이미지를 읽어옵니다.\n",
    "    image = cv2.imread(input_image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"이미지를 로드할 수 없습니다.\")\n",
    "\n",
    "    # 이미지를 RGB로 변환합니다.\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 찾기 위해 주요 랜드마크를 가져옵니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "\n",
    "            # 홍채 영역의 좌표를 가져옵니다.\n",
    "            for landmark in iris_landmarks:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "    # 결과 이미지를 지정한 경로에 저장합니다.\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# 테스트할 이미지 경로를 지정합니다.\n",
    "input_image_path = 'C:/Users/User/Desktop/programs/1234.jpg'\n",
    "output_image_path = 'C:/Users/User/Desktop/programs/marked_iris_image.jpg'\n",
    "\n",
    "# 함수 실행 및 결과 저장\n",
    "marked_image = mark_iris(input_image_path, output_image_path)\n",
    "\n",
    "# 결과 이미지를 화면에 표시합니다.\n",
    "cv2.imshow('Marked Iris Image', marked_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5696bb93-76de-450b-a729-a17c3878df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#홍채 가우시안 블러링\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "def blur_iris(input_image_path, output_image_path):\n",
    "    # 이미지를 읽어옵니다.\n",
    "    image = cv2.imread(input_image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"이미지를 로드할 수 없습니다.\")\n",
    "\n",
    "    # 이미지를 RGB로 변환합니다.\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 찾기 위해 주요 랜드마크를 가져옵니다.\n",
    "            left_iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 473)\n",
    "            ]\n",
    "            right_iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(473, 478)\n",
    "            ]\n",
    "\n",
    "            # 홍채 영역의 좌표를 가져옵니다.\n",
    "            left_iris_points = np.array([[\n",
    "                int(landmark.x * image.shape[1]),\n",
    "                int(landmark.y * image.shape[0])\n",
    "            ] for landmark in left_iris_landmarks])\n",
    "            right_iris_points = np.array([[\n",
    "                int(landmark.x * image.shape[1]),\n",
    "                int(landmark.y * image.shape[0])\n",
    "            ] for landmark in right_iris_landmarks])\n",
    "\n",
    "            # 블러 처리를 위해 홍채 영역을 감싸는 컨벡스 헐(Convex Hull)을 계산합니다.\n",
    "            left_hull = cv2.convexHull(left_iris_points)\n",
    "            right_hull = cv2.convexHull(right_iris_points)\n",
    "\n",
    "            # 블러 처리를 위한 마스크를 생성합니다.\n",
    "            mask = np.zeros_like(image, dtype=np.uint8)\n",
    "            cv2.fillConvexPoly(mask, left_hull, (255, 255, 255))\n",
    "            cv2.fillConvexPoly(mask, right_hull, (255, 255, 255))\n",
    "\n",
    "            # 원본 이미지를 블러 처리합니다.\n",
    "            blurred_image = cv2.GaussianBlur(image, (51, 51), 13)\n",
    "\n",
    "            # 마스크를 이용해 블러 처리된 홍채 영역을 원본 이미지에 합성합니다.\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            image_masked = cv2.bitwise_and(image, mask_inv)\n",
    "            blurred_iris = cv2.bitwise_and(blurred_image, mask)\n",
    "            image = cv2.add(image_masked, blurred_iris)\n",
    "\n",
    "    # 결과 이미지를 지정한 경로에 저장합니다.\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# 테스트할 이미지 경로를 지정합니다.\n",
    "input_image_path = 'C:/Users/User/Desktop/programs/1234.jpg'\n",
    "output_image_path = 'C:/Users/User/Desktop/programs/blurred_iris_image.jpg'\n",
    "\n",
    "# 함수 실행 및 결과 저장\n",
    "blurred_image = blur_iris(input_image_path, output_image_path)\n",
    "\n",
    "# 결과 이미지를 화면에 표시합니다.\n",
    "cv2.imshow('Blurred Iris Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "807d4615-5fbb-46a6-9651-6f49425d4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 홍채영역 트래킹과 지문영역 블러링 (합침) \n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=10)\n",
    "\n",
    "def calculate_distance(landmark1, landmark2, width, height):\n",
    "    x1, y1 = int(landmark1.x * width), int(landmark1.y * height)\n",
    "    x2, y2 = int(landmark2.x * width), int(landmark2.y * height)\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "def blur_fingerprint_area(image, landmarks):\n",
    "    h, w, _ = image.shape\n",
    "    # 엄지손가락 끝과 새끼손가락 끝 사이의 거리 계산\n",
    "    thumb_tip = landmarks[4]\n",
    "    pinky_tip = landmarks[20]\n",
    "    distance = calculate_distance(thumb_tip, pinky_tip, w, h)\n",
    "    \n",
    "    # 거리에 따라 블러 크기 조정\n",
    "    blur_radius = int(max(15, min(50, distance // 4)))\n",
    "    if blur_radius % 2 == 0:  # 홀수로 만들기\n",
    "        blur_radius += 1\n",
    "    ksize = (blur_radius, blur_radius)\n",
    "\n",
    "    # 블러 처리 범위 조정\n",
    "    blur_size = int(max(5, min(50, distance // 30)))\n",
    "    \n",
    "    for i in range(4, 21, 4):  # 각 손가락의 끝부분 (지문이 있는 부분) 인덱스\n",
    "        x = int(landmarks[i].x * w)\n",
    "        y = int(landmarks[i].y * h)\n",
    "        # 지문 부분 주변의 사각형 영역 설정\n",
    "        x_start, y_start = max(0, x-blur_size), max(0, y-blur_size)\n",
    "        x_end, y_end = min(w, x+blur_size), min(h, y+blur_size)\n",
    "        # 블러 처리할 영역이 유효한지 확인\n",
    "        if x_start < x_end and y_start < y_end:\n",
    "            image[y_start:y_end, x_start:x_end] = cv2.GaussianBlur(image[y_start:y_end, x_start:x_end], ksize, 10)\n",
    "    return image\n",
    "\n",
    "def blur_iris_area(image, iris_landmarks):\n",
    "    h, w, _ = image.shape\n",
    "    # 홍채 랜드마크들 간의 평균 거리를 계산\n",
    "    distances = [\n",
    "        calculate_distance(iris_landmarks[i], iris_landmarks[j], w, h)\n",
    "        for i in range(len(iris_landmarks)) for j in range(i + 1, len(iris_landmarks))\n",
    "    ]\n",
    "    average_distance = sum(distances) / len(distances)\n",
    "    \n",
    "    # 거리에 따라 블러 크기 조정\n",
    "    blur_radius = int(max(1, min(30, average_distance // 16)))\n",
    "    if blur_radius % 2 == 0:  # 홀수로 만들기\n",
    "        blur_radius += 1\n",
    "    ksize = (blur_radius, blur_radius)\n",
    "\n",
    "    for landmark in iris_landmarks:\n",
    "        x = int(landmark.x * w)\n",
    "        y = int(landmark.y * h)\n",
    "        # 블러 처리할 영역 설정\n",
    "        x_start, y_start = max(0, x-blur_radius), max(0, y-blur_radius)\n",
    "        x_end, y_end = min(w, x+blur_radius), min(h, y+blur_radius)\n",
    "        if x_start < x_end and y_start < y_end:\n",
    "            image[y_start:y_end, x_start:x_end] = cv2.GaussianBlur(image[y_start:y_end, x_start:x_end], ksize, 30)\n",
    "    return image\n",
    "\n",
    "# 웹캠 입력을 받습니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # 성능을 향상시키기 위해 이미지를 쓰지 않고 참조합니다.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    # MediaPipe Hands 처리를 합니다.\n",
    "    hand_results = hands.process(image)\n",
    "\n",
    "    # 이미지에 출력을 그리기 위해 다시 이미지를 BGR로 변환합니다.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # 홍채 영역을 강조하기 위해 주요 랜드마크를 표시합니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "            image = blur_iris_area(image, iris_landmarks)\n",
    "\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            image = blur_fingerprint_area(image, hand_landmarks.landmark)\n",
    "\n",
    "    cv2.imshow('MediaPipe Iris and Hand Tracking', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
