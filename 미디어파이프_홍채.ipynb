{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68536ae4-6b39-4dad-a166-c9c7e9698920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#미디어파이프를 이용해서 홍채영역 실시간 트래킹\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "# 웹캠 입력을 받습니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # 성능을 향상시키기 위해 이미지를 쓰지 않고 참조합니다.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    # 이미지에 출력을 그리기 위해 다시 이미지를 BGR로 변환합니다.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 강조하기 위해 주요 랜드마크를 표시합니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "            for landmark in iris_landmarks:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "    cv2.imshow('MediaPipe Iris Tracking', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6068ace-5518-42e2-85d2-8a2382fa08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사진 입력시 홍채영역 마킹\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "def mark_iris(input_image_path, output_image_path):\n",
    "    # 이미지를 읽어옵니다.\n",
    "    image = cv2.imread(input_image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"이미지를 로드할 수 없습니다.\")\n",
    "\n",
    "    # 이미지를 RGB로 변환합니다.\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 찾기 위해 주요 랜드마크를 가져옵니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "\n",
    "            # 홍채 영역의 좌표를 가져옵니다.\n",
    "            for landmark in iris_landmarks:\n",
    "                x = int(landmark.x * image.shape[1])\n",
    "                y = int(landmark.y * image.shape[0])\n",
    "                cv2.circle(image, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "    # 결과 이미지를 지정한 경로에 저장합니다.\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# 테스트할 이미지 경로를 지정합니다.\n",
    "input_image_path = 'C:/Users/User/Desktop/programs/1234.jpg'\n",
    "output_image_path = 'C:/Users/User/Desktop/programs/marked_iris_image.jpg'\n",
    "\n",
    "# 함수 실행 및 결과 저장\n",
    "marked_image = mark_iris(input_image_path, output_image_path)\n",
    "\n",
    "# 결과 이미지를 화면에 표시합니다.\n",
    "cv2.imshow('Marked Iris Image', marked_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5696bb93-76de-450b-a729-a17c3878df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#홍채 가우시안 블러링\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "def blur_iris(input_image_path, output_image_path):\n",
    "    # 이미지를 읽어옵니다.\n",
    "    image = cv2.imread(input_image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"이미지를 로드할 수 없습니다.\")\n",
    "\n",
    "    # 이미지를 RGB로 변환합니다.\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    results = face_mesh.process(image_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # 홍채 영역을 찾기 위해 주요 랜드마크를 가져옵니다.\n",
    "            left_iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 473)\n",
    "            ]\n",
    "            right_iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(473, 478)\n",
    "            ]\n",
    "\n",
    "            # 홍채 영역의 좌표를 가져옵니다.\n",
    "            left_iris_points = np.array([[\n",
    "                int(landmark.x * image.shape[1]),\n",
    "                int(landmark.y * image.shape[0])\n",
    "            ] for landmark in left_iris_landmarks])\n",
    "            right_iris_points = np.array([[\n",
    "                int(landmark.x * image.shape[1]),\n",
    "                int(landmark.y * image.shape[0])\n",
    "            ] for landmark in right_iris_landmarks])\n",
    "\n",
    "            # 블러 처리를 위해 홍채 영역을 감싸는 컨벡스 헐(Convex Hull)을 계산합니다.\n",
    "            left_hull = cv2.convexHull(left_iris_points)\n",
    "            right_hull = cv2.convexHull(right_iris_points)\n",
    "\n",
    "            # 블러 처리를 위한 마스크를 생성합니다.\n",
    "            mask = np.zeros_like(image, dtype=np.uint8)\n",
    "            cv2.fillConvexPoly(mask, left_hull, (255, 255, 255))\n",
    "            cv2.fillConvexPoly(mask, right_hull, (255, 255, 255))\n",
    "\n",
    "            # 원본 이미지를 블러 처리합니다.\n",
    "            blurred_image = cv2.GaussianBlur(image, (51, 51), 13)\n",
    "\n",
    "            # 마스크를 이용해 블러 처리된 홍채 영역을 원본 이미지에 합성합니다.\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "            image_masked = cv2.bitwise_and(image, mask_inv)\n",
    "            blurred_iris = cv2.bitwise_and(blurred_image, mask)\n",
    "            image = cv2.add(image_masked, blurred_iris)\n",
    "\n",
    "    # 결과 이미지를 지정한 경로에 저장합니다.\n",
    "    cv2.imwrite(output_image_path, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "# 테스트할 이미지 경로를 지정합니다.\n",
    "input_image_path = 'C:/Users/User/Desktop/programs/1234.jpg'\n",
    "output_image_path = 'C:/Users/User/Desktop/programs/blurred_iris_image.jpg'\n",
    "\n",
    "# 함수 실행 및 결과 저장\n",
    "blurred_image = blur_iris(input_image_path, output_image_path)\n",
    "\n",
    "# 결과 이미지를 화면에 표시합니다.\n",
    "cv2.imshow('Blurred Iris Image', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807d4615-5fbb-46a6-9651-6f49425d4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 홍채영역 트래킹과 지문영역 블러링 (합침) (6/9수정)\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "# MediaPipe 솔루션을 초기화합니다.\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5)\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(max_num_hands=10)\n",
    "\n",
    "def calculate_distance(landmark1, landmark2, width, height):\n",
    "    x1, y1 = int(landmark1.x * width), int(landmark1.y * height)\n",
    "    x2, y2 = int(landmark2.x * width), int(landmark2.y * height)\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "def calculate_finger_length(landmarks, width, height):\n",
    "    # 손가락의 길이를 측정하기 위해 각 손가락의 관절 길이를 합산합니다.\n",
    "    finger_lengths = []\n",
    "    for finger_indices in [(4, 3, 2), (8, 7, 6), (12, 11, 10), (16, 15, 14), (20, 19, 18)]:\n",
    "        finger_length = 0\n",
    "        for i in range(len(finger_indices) - 1):\n",
    "            finger_length += calculate_distance(landmarks[finger_indices[i]], landmarks[finger_indices[i+1]], width, height)\n",
    "        finger_lengths.append(finger_length)\n",
    "    return max(finger_lengths)\n",
    "\n",
    "def blur_fingerprint_area(image, landmarks):\n",
    "    h, w, _ = image.shape\n",
    "    # 손가락 길이 계산\n",
    "    finger_length = calculate_finger_length(landmarks, w, h)\n",
    "    \n",
    "    # 거리에 따라 블러 크기 조정\n",
    "    blur_radius = int(max(15, min(50, finger_length // 4)))\n",
    "    if blur_radius % 2 == 0:  # 홀수로 만들기\n",
    "        blur_radius += 1\n",
    "    ksize = (blur_radius, blur_radius)\n",
    "\n",
    "    # 블러 처리 범위 조정\n",
    "    blur_size = int(max(8, min(50, finger_length // 15)))\n",
    "    \n",
    "    for i in range(4, 21, 4):  # 각 손가락의 끝부분 (지문이 있는 부분) 인덱스\n",
    "        x = int(landmarks[i].x * w)\n",
    "        y = int(landmarks[i].y * h)\n",
    "        # 지문 부분 주변의 사각형 영역 설정\n",
    "        x_start, y_start = max(0, x-blur_size), max(0, y-blur_size)\n",
    "        x_end, y_end = min(w, x+blur_size), min(h, y+blur_size)\n",
    "        # 블러 처리할 영역이 유효한지 확인\n",
    "        if x_start < x_end and y_start < y_end:\n",
    "            image[y_start:y_end, x_start:x_end] = cv2.GaussianBlur(image[y_start:y_end, x_start:x_end], ksize, 10)\n",
    "    return image\n",
    "\n",
    "def blur_iris_area(image, iris_landmarks):\n",
    "    h, w, _ = image.shape\n",
    "    \n",
    "    # 홍채 랜드마크의 최소 및 최대 x, y 좌표 찾기\n",
    "    x_min = min(int(landmark.x * w) for landmark in iris_landmarks)\n",
    "    y_min = min(int(landmark.y * h) for landmark in iris_landmarks)\n",
    "    x_max = max(int(landmark.x * w) for landmark in iris_landmarks)\n",
    "    y_max = max(int(landmark.y * h) for landmark in iris_landmarks)\n",
    "    \n",
    "    # 블러 크기 설정\n",
    "    blur_radius = int(max(2, min(5, (x_max - x_min) // 42)))\n",
    "    if blur_radius % 2 == 0:  # 홀수로 만들기\n",
    "        blur_radius += 1\n",
    "    ksize = (blur_radius, blur_radius)\n",
    "\n",
    "    # 블러 처리할 영역 설정\n",
    "    x_start, y_start = max(0, x_min - blur_radius), max(0, y_min - blur_radius)\n",
    "    x_end, y_end = min(w, x_max + blur_radius), min(h, y_max + blur_radius)\n",
    "    \n",
    "    if x_start < x_end and y_start < y_end:\n",
    "        image[y_start:y_end, x_start:x_end] = cv2.GaussianBlur(image[y_start:y_end, x_start:x_end], ksize, 15)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# 웹캠 입력을 받습니다.\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # 성능을 향상시키기 위해 이미지를 쓰지 않고 참조합니다.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # MediaPipe Face Mesh 처리를 합니다.\n",
    "    face_results = face_mesh.process(image)\n",
    "\n",
    "    # MediaPipe Hands 처리를 합니다.\n",
    "    hand_results = hands.process(image)\n",
    "\n",
    "    # 이미지에 출력을 그리기 위해 다시 이미지를 BGR로 변환합니다.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if face_results.multi_face_landmarks:\n",
    "        for face_landmarks in face_results.multi_face_landmarks:\n",
    "            # 홍채 영역을 강조하기 위해 주요 랜드마크를 표시합니다.\n",
    "            iris_landmarks = [\n",
    "                face_landmarks.landmark[i] for i in range(468, 478)\n",
    "            ]\n",
    "            image = blur_iris_area(image, iris_landmarks)\n",
    "\n",
    "    if hand_results.multi_hand_landmarks:\n",
    "        for hand_landmarks in hand_results.multi_hand_landmarks:\n",
    "            image = blur_fingerprint_area(image, hand_landmarks.landmark)\n",
    "\n",
    "    cv2.imshow('MediaPipe Iris and Hand Tracking', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c60b8-f418-49f8-9557-8c93dd9c84e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
